---
title: "Tidying Data"
subtitle: "Introduction to R For Biologists and Bioinformatics"
author: "Dr Stevie Pederson"
institute: |
  | Black Ochre Data Labs
  | Telethon Kids Institute
date: "2023-09-17"
date-format: long
title-slide-attributes:
    data-background-color: "#3c3c44"
    data-background-image: assets/bodl_logo_white_background.jpg
    data-background-opacity: "0.3"
    data-background-size: "90%"
editor: source
format: 
  revealjs:
    theme: [../custom.scss]
    code-line-numbers: false
    width: 1024
    height: 768
    sansfont: Times New Roman
    logo: assets/bodl_logo_white_background.jpg
  html: 
    output-file: tidying_data.html
    embed-resources: true
    toc: true
    toc-depth: 1
knitr: 
  opts_chunk: 
    echo: true
    include: true
    warning: false
    message: false
    fig.align: center
---

```{r setwd, echo=FALSE}
if (interactive()) setwd(here::here("docs"))
knitr::opts_chunk$set(results = "hide")
```


# Tidying Data {background-color="#3c3c44" background-image=https://www.tidyverse.org/images/hex-tidyverse.png background-size="30%" background-opacity="0.4"}

## Section Setup

- Clear your `R` Environment
- Create a new script called 'TidyingData.R'
- Load the tidyverse

```{r}
library(tidyverse)
```

. . .

<br>We'll cover:

- More challenging data importing
- `SQL-` and `Excel-`like functions in `dplyr`
- Pivoting and manipulating using `tidyr`

## Importing Data

- We'll use a new dataset for this section: `data/transport.csv`
- Open a Preview using your favourite method *before* we import into `R`

::: {.incremental}

- Note a few challenges here:
    + Two idiots have put comments at the top of the file
    + There are no column names
    + The first column appears to just be the row numbers
    
:::
    
## Importing Data

Planning the import:

::: {.incremental}

- How do we handle the comments? 
    + Check the help page (`?read_csv`)
    + The argument `comment` allows us to tell `read_csv()` which lines are comments
- How do we handle the missing `col_names`?
    + We can provide a character vector of column names
- Can we skip the first column?
    + Yes, we can tell `read_csv` what data type is in each column
    + Also allows us to skip columns

:::


## Importing Data

- By constructing our code carefully <br> $\implies$ import this file as many times as we want
- We have:
    1. Set `comment = "#"` to skip lines beginning with `#`
    2. Provided a vector of appropriate column names
    3. Asked `read_csv()` to skip the first column

```{r load-transport}
cols <- c("gender", "name", "weight", "height", "method")
transport <- read_csv(
  "data/transport.csv",
  comment = "#", col_names = cols, col_types = "-ccnnc"
)
```

. . .

So we have a `r nrow(transport)` x `r ncol(transport)` `data frame`

```{r}
glimpse(transport)
```


## Logical Tests

- Before we start to explore `transport` $\implies$ **Logical Tests**

::: {.incremental}

- Is Equal To: `==`
- Not equal: `!=`
- Or: `|`
- And: `&`
- Less than: `<`
- Less than or equal: `<=`

:::

## Logical Tests

```{r, results='hide'}
x <- c(1:5)
x == 5
x != 5
x > 3
x > 3 | x == 2
```

. . .

Can also return which positions within a logical vector are `TRUE`

```{r}
transport$height > 180
which(transport$height > 180)
```


# The package `dplyr` {background-color="#3c3c44" background-image=https://swag.rstudio.com/uploads/1/3/1/3/131335021/s815253891256106552_p2_i4_w660.png background-size="40%" background-opacity="0.5"}

## Using `dplyr`

- `dplyr` is a core `tidyverse` package
- Inspired by SQL operations
- Uses similar function names to SQL 

. . .

- So do lots of other packages
    + Quite easy to side-step these issues if you know how...

## Starting with `dplyr::select()` 

- The function `select()` allows you to select columns by name
- The `tibble` must be given as the first argument
    + Defined in the help page as `.data`

```{r}
select(transport, gender, name, weight)
```

Or by position

```{r}
select(transport, 1:3)
```

. . .

<br>

- **NB: We have not modified the original object!**
    + Only when we use the `<-` symbol

## Starting with `dplyr::select()` 

- We can also remove columns using the minus (`-`) sign

```{r}
select(transport, -2)
select(transport, -name)
```

<br>

__Discuss: Would removing by name or position by the best?__

::: {.notes}
If we remove by name and the column has already been removed, we will get an error
:::


## Starting with `dplyr::select()` 

The `select()` function has a few helper functions

- `starts_with()`, `ends_with()`, `contains()`, `matches()`
    + All take a single text string to match amongst column mames
- `one_of()`, `any_of()`, `all_of()` 
    + Take a character vector listing column names
- `everything()`, `last_col()`
- Provided in the package `tidyselect` (always loaded by `dplyr`)

```{r}
select(transport, ends_with("ght"))
select(transport, contains("t"))
```


<!-- ## Starting with `dplyr::select()`  -->

<!-- __So far, we haven't changed the original object__ -->

<!-- We can overwrite this anytime (sometimes we will by accident) -->

<!-- ```{r} -->
<!-- transport <- select(transport, -name) -->
<!-- transport -->
<!-- ``` -->

<!-- Now we have removed the `name` column -->

<!-- ## Starting with `dplyr::select()`  -->

<!-- - To get the column back, we need to reload the `.csv` file -->

<!-- ```{r, echo=FALSE, eval = TRUE} -->
<!-- transport <- read_csv( -->
<!--   "data/transport.csv", -->
<!--   comment = "#", col_names = FALSE, na = "-", col_types = "-ccnnc" -->
<!-- ) -->
<!-- colnames(transport) <- c("gender", "name", "weight", "height", "method") -->
<!-- ``` -->


## Using `dplyr::filter()` 

- We can use our logical tests to filter the data
- Again we need to specify the `tibble` as the first argument

```{r}
filter(transport, method == "car")
filter(transport, method == "car", gender == "female")
```

. . .

- Using two queries with a comma is the same as typing `&`
    + Queries are executed in order

. . .

(We'll fix those weird gender entries very soon)

## Using `dplyr::arrange()` 

We can sort on one or more columns

```{r}
arrange(transport, height)
arrange(transport, method, height)
```

. . .

<br>We can change to descending order using `desc()`

```{r}
arrange(transport, desc(height))
```

# Combining Functions {background-color="#3c3c44" background-image=https://magrittr.tidyverse.org/logo.png background-size="40%" background-opacity="0.5"}

```{r reset-results-to-visible, echo = FALSE}
knitr::opts_chunk$set(results = "markup")
```


## Combining Functions

- This is where `dplyr` and the `tidyverse` steps up a gear
- We can chain functions together using `|>`
- This behaves like a pipe (`|`) in the bash shell
- Originally introduced as `%>%` from the package `magrittr`
    + `|>` Added at R 4.2.0
    + Older code may contain `%>%`

. . .

> Both `|>` and `%>%` place the **output of the first function** as the **first argument** of the next function!

. . .

<br>(I personally haven't made the shift from `%>%` to `|>` yet)

::: {.notes}
- Apparently `|>` has some advantages, but I haven't figured them out yet
- I understand the nuances of `%>%` so am sticking with it
:::

## Combining Functions

:::: {.columns}

::: {.column}

```{r}
filter(transport, method == "bike")
```

:::

::: {.column}

```{r}
transport |> filter(method == "bike")
```

:::

::::

::: {.fragment}
<br>Both of these are identical
:::


## Combining Functions

Now we can perform [multiple operations]{.underline}!

```{r}
transport |> filter(method == "bike") |> arrange(weight)
```

. . .

<br>There is __no limit__ to the number of operations you can chain together

## For the technically minded {visibility="hidden"}

1. Each function in `dplyr` takes a `data.frame` as the first argument
2. Each function returns a `data.frame`

```{r}
transport |> filter(method == "bike") |> arrange(height)
```

. . .

1. The `|>` placed `transport` into the first argument of `filter()`
2. The output of `filter()` was a `data.frame` <br>$\implies$ this was placed as the first argument to `arrange()`


## Using `dplyr::mutate()`

We can add extra columns using `mutate()`

```{r}
transport |> mutate(height_m = height/100)
```


## Using `dplyr::mutate()`

Once we've added a column, we can refer to it by name and keep adding

```{r}
transport |> 
  mutate(
    height_m = height/100, 
    BMI = weight / height_m^2
  )
```

## Using `dplyr::mutate()`

We can also modify existing columns *in place*

```{r}
transport |> mutate(height = height/100)
```

. . .

<br>
__Have we changed the original__ `object` yet?

## Using `dplyr::rename()`

Can use the function `rename()`

```{r}
transport |> rename(height_cm = height)
```

## Using `dplyr::rename()`

Now we can go crazy with multiple processes

```{r}
transport |>
  rename(height_cm = height) |>
  mutate(
      height_m = height_cm/100, 
      BMI = weight / height_m^2
  ) |>
  filter(BMI > 25)
```

## Combining with `case_when()`

- This is how we can tidy our strange values in the `gender` column
    + First check what is there
    + `pull()` grabs a single column as a vector (like `$`)

```{r}
transport |>
    pull("gender") |>
    table()
```

::: {.incremental}

- We should use the majority coding format $\implies$ `female` or `male`
    + Both `F` and `Female` $\implies$ `female`
    + Both `M` and `Male` $\implies$ `male`
    + This will also become a `factor` after being corrected
    
:::
    
## Combining with `case_when()`

```{r}
transport |>
    mutate(
        gender = case_when(
            gender == "F" ~ "female",
            gender == "Female" ~ "female",
            gender == "female" ~ "female",
            gender == "M" ~ "male",
            gender == "Male" ~ "male",
            gender == "male" ~ "male"
        )
    ) |>
    pull("gender") |>
    table()
```

. . .

<br>**Could we have made this shorter?**


## Combining with `case_when()`

- `case_when()` steps through conditions hierarchically
    + Once `TRUE` is returned that value is excluded from future tests
    + Don't need to reassign `"female"` or `"male"` values
    
. . .

```{r}
transport |>
    mutate(
        gender = case_when(
            gender == "F" ~ "female",
            gender == "Female" ~ "female",
            gender == "M" ~ "male",
            gender == "Male" ~ "male",
            TRUE ~ gender
        )
    ) |>
    pull("gender") |>
    table()
```

. . .

- This final `TRUE` catches everything that hasn't yet been `TRUE`


## Combining with `case_when()`

- We could also shorten further using `str_to_lower`

```{r}
transport |>
    mutate(
        gender = case_when(
            gender == "F" ~ "female",
            gender == "M" ~ "male",
            TRUE ~ str_to_lower(gender)
        )
    ) |>
    pull("gender") |>
    table()
```

. . .

<br>I would do this during data import

## Modifying an object during import

- My full import code chunk might be as below <br>$\implies$ everything is done once at import

```{r}
cols <- c("gender", "name", "weight", "height", "method")
transport <- "data/transport.csv" |>
    read_csv(comment = "#", col_names = cols, col_types = "-ccnnc") |>
    mutate(
        
        ## Correct erroneous gender encoding, the set as a factor
        gender = case_when(
            gender == "F" ~ "female",
            gender == "M" ~ "male",
            TRUE ~ str_to_lower(gender)
        ),
        gender = as.factor(gender),
        
        ## Set method as a factor
        method = factor(method, levels = c("car", "bike")),
        
        ## Calculate BMI
        BMI = weight / (0.01 * height) ^ 2
    )
```

::: {.notes}
- Note that we manually set the factor levels for the method, but went with alphanumeric for gender
- We also imported, found the problem, then modified our import code
    + This is a common strategy $\implies$ load then fix
:::

## Getting Summaries

We can get summaries for entire columns

```{r}
transport |> 
  summarise(
      mn_weight = mean(weight),
      mn_height = mean(height),
      mn_bmi = mean(BMI)
  )
```

## Getting Summaries

We can group categorical variables by their levels

```{r}
transport |>
  summarise(
      mn_weight = mean(weight),
      mn_height = mean(height), 
      mn_bmi = mean(BMI),
      .by = gender
  )
```


## Getting Group Summaries

Or combinations of levels

```{r}
transport |>
  summarise(
      mn_weight = mean(weight),
      mn_height = mean(height), 
      mn_bmi = mean(BMI),      
      .by = c(gender, method)
  )
```

. . .

<br>Can use any function that spits out a single value

- `sd()`, `min()`, `median()`

## Getting Group Summaries

Count how many entries in each combination using `n()`

```{r}
transport |>
    summarise(
        n = n(),
        mn_weight = mean(weight),
        mn_height = mean(height), 
        mn_bmi = mean(BMI),      
        .by = c(gender, method)
    )
```

# Applying Functions Across Multiple Columns {background-color="#3c3c44"}

## Applying Functions Across Multiple Columns

- Use the helper function `across()`
- Can apply `starts_with()`, `ends_with()`, `contains()` syntax to select variables/columns
- Pass a function to the `.fns` argument
    
## Applying Functions Across Multiple Columns

```{r}
transport |>
    summarise(
        across(.cols = ends_with("ght"), .fns = mean),
        .by = c(gender, method)
    )
```

## Applying Multiple Functions

- We can pass multiple functions to multiple columns
    + Naming these functions makes the output clearer

```{r}
transport |>
  summarise(
    n = n(),
    across(ends_with("ght"), .fns = c(mn = mean, sd = sd)),
    .by = c(gender, method)
  )
```

# Combining Data Frames {background-color="#3c3c44"}

## Combining Data Frames

`dplyr` has some very useful functions for combining `data.frame` objects

- `bind_rows()` and `bind_cols()`
- `left_join()`, `right_join()` and `full_join()`

<!-- Amazingly, we've just had data from `Tony` and he's a 83kg car-driver, who is 177.3cm tall. -->

<!-- - We can manually create a `tibble` just for him -->

<!-- ## Combining Data Frames -->

<!-- ```{r} -->
<!-- tony <- tibble( -->
<!--   gender = "male", -->
<!--   name = "Tony", -->
<!--   weight = 83, -->
<!--   height = 177.3, -->
<!--   method = "car" -->
<!-- ) -->
<!-- ``` -->

<!-- We can add his data using `bind_rows()` -->

<!-- ```{r} -->
<!-- bind_rows(tony, transport) -->
<!-- ``` -->


## Combining Data Frames

```{r}
#| output-location: fragment
contacts <- read_csv("data/contacts.csv", col_types = "cc")
glimpse(contacts)
glimpse(transport)
```


## Combining Data Frames 

**Do these objects look compatible?**

::: {.incremental}

- Some may be missing in one of the objects
- The values in the `name` column look similar
- In a different order

[**How do we combine these?**]{.fragment .fade-in}

:::

## `dplyr::left_join()`

- We can use the first `tibble` as the template: `left_join()`

```{r}
left_join(transport, contacts, by = "name")
```

. . .

- Any `name` entries missing from the second `tibble` (`contacts`) will become `NA` in the column `contact`

```{r}
transport |>
    left_join(contacts, by = "name") |>
    filter(is.na(contact))
```


## `dplyr::right_join()`

- We can use the second object as the template: `right_join()`

```{r}
transport |> 
    right_join(contacts, by = "name") |>
    tail()
```

- Any missing from the first `tibble` (`transport`) will become `NA` where missing

## `dplyr::full_join()`

- Combine everything using `full_join()`

```{r}
transport |>
    full_join(contacts, by = "name") |>
    filter(is.na(gender) | is.na(contact))
```

. . .

Will be missing values in both directions

# Reshaping Data {background-color="#3c3c44" background-image=https://tidyr.tidyverse.org/logo.png background-size="30%" background-opacity="0.5"}

```{r, echo = FALSE}
knitr::opts_chunk$set(eval = FALSE)
```


## Reshaping your data

- This dataset is in what we refer to as `wide` form
- We have a row of measurements for each individual
- The information is _structured around the individual_

In `long` form, the information is _structured around the measurement_

## Reshaping your data | From Wide to Long

```{r}
timeCourse <- read_csv("data/timeCourse.csv")
timeCourse
```

This is a time course:

- Measuring log-change in GFP intensity
- Two treatments (`Tx`) A & B 
- Also have identifier column: `Mouse`

## From Wide to Long

The basic function is `pivot_longer()`

- Part of the package `tidyr`
- Key arguments are:
    - `cols`: which columns are shifting to long form
    - `names_to`: What shall we call the column with the old column names
    - `values_to`: What shall we call the column with the values
    
## From Wide to Long

```{r}
timeCourse |>
  pivot_longer(
    cols = starts_with("day"),
    names_to = "Day",
    values_to = "logFC"
  )
```

Many functions require data to be in this format

## From Wide to Long

__How could we get means for each treatment/day from the original data?__

 . . .

```{r}
timeCourse |>
  pivot_longer(
    cols = starts_with("day"), names_to = "Day", values_to = "logFC"
  ) |>
  group_by(Tx, Day) |>
  summarise(mn_change = mean(logFC))
```

. . .

__Can we add the standard deviation?__

## From Wide to Long

__Can we add the standard deviation?__

 . . .

```{r}
timeCourse |>
  pivot_longer(
    cols = starts_with("day"), names_to = "Day", values_to = "logFC"
  ) |>
  group_by(Tx, Day) |>
  summarise(across(all_of("logFC"), .fns = c(mn = mean, sd = sd)))
```

## From Long To Wide

- We can also take our data from long to wide form
- Key arguments are `names_from` and `values_from`
- Often have to deal with missing values in this context

```{r}
transport |>
  mutate(status = 1) |>
  pivot_wider(
    names_from = "method", values_from = "status"
  )
```


## From Long To Wide

- We can also take our data from long to wide form
- Key arguments are `names_from` and `values_from`
- Often have to deal with missing values in this context

```{r}
transport |>
  mutate(status = 1) |>
  pivot_wider(
    names_from = "method", values_from = "status", values_fill = 0
  )
```


## Combining and Separating Columns

There really is no end to the possible situations we find

```{r}
pcr <- read_csv("data/PCR.csv")
pcr
```

. . .

Here, both treatment and timepoint are in the column name

## Combining and Separating Columns

Let's transform using pivot longer

```{r}
pcr |>
  pivot_longer(cols = ends_with("hr"), names_to = "group", values_to = "Ct")
```

. . .

We need to separate the original column names: `separate()`

```{r}
pcr |>
  pivot_longer(cols = ends_with("hr"), names_to = "group", values_to = "Ct") |>
  separate(
    col = "group", into = c("Treat", "Timepoint")
  )
```

. . .

- The separator was set by default to be any non-alpha-numeric symbol
- This is a pattern known as a *regular expression*

## Combining and Separating Columns

The reverse operation is `unite()`

```{r}
transport |>
  unite(
    col = "group", all_of(c("gender", "method")), sep = "-"
  )
```

. . .

We can also perform this, retaining the original column

```{r}
transport |>
  unite(
    col = "group", all_of(c("gender", "method")), sep = "-",
    remove = FALSE
  )
```

# The `tidyverse` {background-color="#3c3c44" background-image=https://tidyverse.tidyverse.org/logo.png background-size="50%" background-opacity="0.5"}

## The `tidyverse`

- The packages `dplyr`, `tidyr` and `readr` are used in most workflows
- Additional near-essential packages: `ggplot2` and `forcats`
- All can be loaded with `library(tidyverse)`
    + A few less obvious packages like `purrr` are also loaded
    
. . .

Nearly **all** my analyses start with `library(tidyverse)`

## Saving Data

- We'll be using `transport` later today
- Please save your edited version (i.e. without missing values)

```{r, eval = FALSE}
write_csv(
  x, # This is where your R object goes
  file, # This is where to save it on your HDD
  na = "NA",
  append = FALSE,
  col_names = !append,
  quote = c("needed", "all", "none"),
  escape = c("double", "backslash", "none"),
  eol = "\n",
  num_threads = readr_threads(),
  progress = show_progress(),
  path = deprecated(),
  quote_escape = deprecated()
)
```

## Saving Data

- We'll be using `transport` later today
- Please save your edited version (i.e. without missing values)

```{r}
write_csv(transport, "data/transport_clean.csv")
```


# Some Final Words {background-color="#3c3c44"}

## Conflicting Function Names

- Many functions in `dplyr` were inspired by SQL
    + Some function names have been used by multiple packages
    + `select()` and `filter()` are most heavily used
- If a weird error occurs, add the package name before the function
    + `dplyr::select()` or `dplyr::filter()`
    + I [always]{.underline} do this for both as a habit
    
. . .
    
```{r, eval = TRUE, echo = TRUE, warning=TRUE, error=TRUE, include=TRUE}
library(GO.db)
transport |> select(gender)
transport |> dplyr::select(gender) |> glimpse()
```


